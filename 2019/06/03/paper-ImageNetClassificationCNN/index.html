<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword" content="">
    <link rel="shortcut icon" href="/img/ironman-draw.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <title>
        
          ImageNet Classification with Deep Convolutional Neural Networks - kwongyangBiog
        
    </title>

    <link rel="canonical" href="http://kwongyang.com/2019/06/03/paper-ImageNetClassificationCNN/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS --> 
    <link rel="stylesheet" href="/css/beantech.min.css">
    
    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css">

    <link rel="stylesheet" href="/css/widget.css">

    <link rel="stylesheet" href="/css/rocket.css">

    <link rel="stylesheet" href="/css/signature.css">

    <link rel="stylesheet" href="/css/toc.css">

    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            background-image: url('background.jpg')
            /*post*/
        
    }
    
    #signature{
        background-image: url('/img/signature/nameSign-white.png');
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#DeepLearning" title="DeepLearning">DeepLearning</a>
                            
                              <a class="tag" href="/tags/#Paper" title="Paper">Paper</a>
                            
                        </div>
                        <h1>ImageNet Classification with Deep Convolutional Neural Networks</h1>
                        <h2 class="subheading">Alex Krizhevsky,Ilya Sutskever,Geoffrey E. Hinton</h2>
                        <span class="meta">
                            Posted by Kwong on
                            2019-06-03
                        </span>
                    </div>
                


                </div>
            </div>
        </div>
    </div>
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">KwongyangBiog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Modify by Yu-Hsuan Yen -->

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <p>本篇论文是加拿大多伦多大学Hinton小组所作的<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></p>
<h2><span id="abstract">Abstract</span></h2><p>我们训练了一个大型的深度卷积神经网络，将ImageNet lsvprc -2010竞赛中的120万幅高分辨率图像分成1000个不同的类。测试数据上，我们实现了前1名和前5名的错误率分别为37.5%和17.0%，大大优于之前的水平。该神经网络有6000万个参数和65万个神经元，由5个卷积层和3个全连接层组成，其中一些卷积层之后是最大汇聚层，最后是1000路softmax。为了使训练更快，我们使用了非饱和神经元和一个非常高效的GPU实现卷积运算。为了减少全连通层的过拟合，我们采用了最近开发的正则化方法“dropout”，该方法被证明是非常有效的。我们还输入了该模型的一个变体在ILSVRC-2012比赛中，获得前5名的测试错误率为15.3%，而第二名的测试错误率为26.2%。</p>
<h2><span id="introduction">Introduction</span></h2><p>目前的目标识别方法主要使用机器学习方法。为了提高性能，我们可以收集更大的数据集，学习更强大的模型，并使用更好的技术来防止过度拟合。直到最近，标记图像的数据集还相对较小，只有数万幅图像。使用这种大小的数据集可以很好地解决简单的识别任务，特别是如果使用保存标签的转换来增强它们。</p>
<p>例如，MNIST数字识别任务的当前最佳错误率(&lt;0.3%)接近人类性能。但现实环境中的物体表现出相当大的变异性，因此，要学会识别它们，有必要使用更大的训练集。的确，小图像数据集的缺点已经得到了广泛的认识(例如，Pinto等人的[21])，但直到最近才有可能收集具有数百万张图像的标记数据集。</p>
<p>新的更大的数据集包括LabelMe[23]，它由数十万张完全分割的图像组成，以及ImageNet[6]，它由超过22000个类别的超过1500万张标记的高分辨率图像组成</p>
<p>要从数以百万计的图像中学习成千上万的物体，我们需要一个具有较大学习能力的模型。然而，对象识别任务的巨大复杂性意味着即使是像ImageNet这样大的数据集也不能指定这个问题，因此我们的模型也应该有大量的先验知识来补偿我们没有的所有数据。</p>
<p>卷积神经网络(CNNs)构成这样一类模型[16、11、13、18、15、22、26]。它们的容量可以通过改变深度和宽度来控制，而且它们还对图像的性质(即统计量的平稳性和像素依赖性的局部性)做出了强有力且基本正确的假设。因此，与具有相似大小层的标准前馈神经网络相比，CNNs具有更少的连接和参数，因此更容易训练，而其理论上最好的性能可能只是略差。</p>
<p>尽管CNNs具有吸引人的特性，尽管其本地架构相对高效，但将其大规模应用于高分辨率图像仍然非常昂贵。幸运的是，当前的gpu与高度优化的2D卷积实现相结合，具有足够强大的功能，可以方便地训练有趣的大型CNNs，而且最近的数据集(如ImageNet)包含足够多的标记示例，可以训练此类模型，而不会出现严重的过拟合。</p>
<p>本文的具体贡献如下:针对ILSVRC-2010和ILSVRC-2012比赛[2]中使用的ImageNet子集，我们训练了迄今为止最大的卷积神经网络之一，并取得了迄今为止在这些数据集中报道过的最好的结果。我们编写了一个高度优化的GPU实现的2D卷积和所有其他训练卷积神经网络固有的操作，我们公开可用。我们的网络包含了许多新的和不寻常的特性，这些特性提高了它的性能，减少了它的培训时间，这些特性在第3节中详细介绍。我们的网络规模使过度拟合成为一个重要的问题，即使有120万个标记的训练示例，所以我们使用了一些有效的技术来防止过度拟合。在第4节中进行了描述。我们最终的网络包含5个卷积和3个全连接层，这个深度似乎很重要:我们发现去掉任何卷积层(每个卷积层包含的参数不超过模型参数的1%)都会导致性能下降。</p>
<p>最后，网络的大小主要受到当前gpu上可用内存的大小和我们愿意忍受的训练时间的大小的限制。我们的网络需要5到6天的时间来训练两个GTX 580 3GB gpu。我们所有的实验都表明，只要等待更快的gpu和更大的数据集可用，我们的结果就可以得到改善。</p>
<h2><span id="the-dataset">The Dataset</span></h2><p>ImageNet是一个包含超过1500万张高分辨率图像的数据集，属于大约22,000个类别。这些图片是从网上收集的，并由亚马逊的人工贴标签者使用Turk crowd-sourcing工具贴上标签。作为Pascal可视对象的一部分挑战，一个名为ImageNet大型视觉识别挑战的年度竞赛<br>(ILSVRC)已被举行。ILSVRC使用ImageNet的一个子集，每个子集中大约有1000个图像1000个类别。总共大约有120万张训练图像50,000张验证图像，以及150000测试图像。</p>
<p>ILSVRC-2010是唯一一个可以使用测试集标签的ILSVRC版本，因此这是我们进行大部分实验的版本。由于我们也在ILSVRC-2012竞赛中进入了我们的模型，所以在第6节中，我们也报告了关于这个版本的数据集的结果，这个版本的测试集标签是不可用的。在ImageNet上，通常报告两个错误率:top-1和top-5，其中top-5错误率是测试图像的一部分，其中正确的标签不在模型认为最可能出现的五个标签中。</p>
<p>ImageNet由可变分辨率的图像组成，而我们的系统需要一个恒定的输入维数。因此，我们将图像降采样到一个固定的分辨率为256X256。给定一个矩形图像，我们首先重新调整图像的大小，使较短的边长度为256，然后从生成的图像中裁剪出中心的256X256块。除了从每个像素中减去训练集上的平均活动外，我们没有以任何其他方式对图像进行预处理。因此，我们将网络训练为像素的原始RGB值(居中)。</p>
<h2><span id="the-architecture">The Architecture</span></h2><p>图2总结了我们的网络架构。它包含八个学习层——五个卷积层和三个全连接层。下面，我们将描述我们的网络架构的一些新奇或不寻常的特性。第3.1-3.4节根据我们对其重要性的估计进行排序，最重要的先排序。</p>
<h3><span id="relu-nonlinearity">ReLU Nonlinearity</span></h3><p>标准方法模型神经元的输出作为其输入 $x$ 的函数 $f(x)$ 与 $f(x) = tanh(x) $ 或 $f(x) = (1 + e^{-x})^{-1}$ 。在梯度下降训练时间方面，这些饱和非线性比非饱和非线性$f(x)=max(0,x)$更慢。在Nair和Hinton[20]之后，我们将这种非线性的神经元称为整流线性单元(ReLUs)。使用ReLUs的深度卷积神经网络的训练速度是使用tanh单元的数倍。这张图表明，如果我们使用传统的饱和神经元模型，我们就无法用这么大的神经网络来进行实验。</p>
<p>我们并不是第一个考虑在CNNs中替代传统神经元模型的人。例如，Jarrett等人的[11]声称非线性$f(x) = |tanh(x)|$在他们的对比类型正化之后，在caltech101数据集中的本地平均池中工作得特别好。<br>然而，在这个数据集中，最主要的问题是防止过度拟合，因此他们观察到的效果不同于我们在使用ReLUs时报告的加速适应训练集的能力。更快的学习速度对大数据集上训练的大型模型的性能有很大的影响。</p>
<h3><span id="training-on-multiple-gpus">Training on Multiple GPUs</span></h3><p>一个GTX 580 GPU只有3GB的内存，这限制了可以在其上训练的网络的最大大小。事实证明，120万个训练实例足以训练一个GPU上无法容纳的网络。因此，我们将网络分布在两个gpu上.当前的gpu特别适合跨gpu并行化，因为它们可以直接读写彼此的内存，而不需要经过主机内存。我们使用的并行化方案本质上是将一半内核(或神经元)放在每个GPU上，还有一个额外的技巧:GPU只在特定的层中通信.这意味着，例如，第3层的内核从第2层的所有内核映射中获取输入。然而，第4层的内核只从位于同一GPU的第3层的内核映射中获取输入。对于交叉验证来说，选择连接模式是一个问题，但这允许我们精确地调整通信量，直到它是计算量的可接受部分。</p>
<p>合成体系结构有点类似“柱状”CNN¸除了我们的列不独立(参见图2)。该方案减少了我们(和前5错误率1.7%和1.2%,分别比净一半的内核在每个卷积层对准一个GPU。双gpu网络的训练时间比单gpu网络略短。</p>
<h3><span id="local-response-normalization">Local Response Normalization</span></h3><p>ReLUs有一个理想的特性，即不需要对输入进行标准化以防止其饱和。如果至少有一些训练例子对ReLU产生积极的输入，学习就会发生在那个神经元上。但是，我们仍然发现下面的局部归一化方案有助于泛化。用 $ a_{x,y}^i $ 表示通过在位置上应用核 $ i $ 计算出的神经元的活动$(x,y)$然后应用ReLU非线性，得到响应归一化活动$b_{x,y}^i$的表达式:</p>
<script type="math/tex; mode=display">b_{x,y}^i = a_{x,y}^i {/} \left( k + \alpha\sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}{(a_{x,y}^i)^2}\right)</script><p>当和运行在n个“相邻”内核映射的相同空间位置上时，n是层中内核的总数。当然，内核映射的顺序是任意的，并在训练开始之前确定。这种反应归一化实现了一种形式的横向抑制，其灵感来自于在真实神经元中发现的类型，在使用不同内核计算的神经元输出之间产生对大型活动的竞争。常数k, n、α和β超参数的值是决定使用一套验证;我们使用k = 2，n = 5，α= 10−4,β= 0.75。在对某些层应用ReLU非线性之后，我们应用了这种归一化(参见3.5节)。</p>
<p>这个方案与Jarrett et al.[11]的局部对比度归一化方案有一些相似之处，但是我们的方案更准确地称为“亮度归一化”，因为我们没有减去平均活动。响应规范化将前1名和前5名的错误率分别降低1.4%和1.2%。在CIFAR-10的四层数据集上验证了该方案的有效性，CNN在没有归一化的情况下测试错误率为13%，在归一化的情况下测试错误率为11%。</p>
<h3><span id="overlapping-pooling">Overlapping Pooling</span></h3><p>CNNs中的汇聚层总结了同一核映射中相邻神经元群的输出。传统上，由相邻的池单元汇总的邻区不会重叠。更精确地说，池层可以被认为是由间隔为s像素的池单元网格组成，每个网格汇总一个以池单元位置为中心的大小为zXz的邻域。如果我们设置s = z，我们将得到传统的本地池，就像CNNs中常用的那样。如果我们设置s&lt;z，我们得到重叠池。这是我们在整个网络中使用的，s = 2 z = 3。该方案将前1名和前5名的错误率降低0.4%与非重叠方案s = 2相比，分别为0.3%;z = 2，输出的尺寸相等。我们通常在训练过程中观察到，具有重叠池的模型发现稍微难以过度匹配。</p>
<h3><span id="overall-architecture">Overall Architecture</span></h3><p>现在我们准备描述CNN的总体架构。如图2所示，网络包含8层权重;前五个是卷积的，其余三个是完全连接的。最后一个全连接层的输出被提供给一个1000路softmax，它产生一个超过1000个类标签的分布。我们的网络将多项式逻辑回归目标最大化，这等价于在预测分布下，将正确标签的log-概率的训练样本均值最大化。</p>
<p>第二层、第四层和第五层卷积层的内核只连接到上一层驻留在同一GPU上的内核映射(见图2)，第三层卷积层的内核连接到第二层的所有内核映射。在完全连接层的神经元连接到前一层的所有神经元。响应归一化层遵循第一层和第二层卷积。最大池化层，如本节所述3.4遵循响应归一化层和第五个卷积层。每个卷积全连通层的输出均采用ReLU非线性。</p>
<p>第一个卷积层对大小为11x11x3的96个核的224x224x3个输入图像进行滤波，步长为4个像素(这是相邻的接收域中心之间的距离核映射中的神经元)。第二个卷积层将第一个卷积层的输出(响应归一化和池化)作为输入，并使用256个大小为5x5x48的内核对其进行过滤。第三、第四和第五卷积层相互连接，不需要任何池化或标准化层。第三个卷积层有384个大小为3x3x256的内核连接到第二卷积层的输出(归一化、池化)。第四个卷积层有384个大小为3x3x192的内核，第五个卷积层有256个核，大小为3x3x192。全连接层各有4096个神经元。</p>
<h2><span id="reducing-overfitting">Reducing Overfitting</span></h2><p>我们的神经网络结构有6000万个参数。尽管ILSVRC的1000个类使得每个训练示例对从图像到标签的映射施加10位的约束，但是如果不进行大量的过拟合，学习这么多参数是不够的。下面，我们将描述两种主要的方法来对抗过度拟合。</p>
<h3><span id="data-augmentation">Data Augmentation</span></h3><p>减少图像数据过拟合最简单、最常见的方法是使用保留标签的转换(如[25,4,5])人为地扩大数据集。我们使用了两种不同的数据增强形式，这两种方法都允许从原始图像生成转换后的图像，并且只需要很少的计算，因此转换后的图像不需要存储在磁盘上。在我们的实现中,转换后的图像是用Python代码在CPU上生成的，而GPU正在对前一批图像进行训练。因此，这些数据增强方案实际上是无需计算的。</p>
<p>数据增强的第一种形式包括生成图像平移和水平反射。我们通过随机抽取224x224个patch(及其水平反射)来实现这一点256x256张图像，然后在这些提取的补丁上训练我们的网络。这将我们的训练集的大小增加了2048倍，尽管由此产生的训练示例当然是高度相互依赖的。<br>如果没有这个方案，我们的网络将遭受严重的过度拟合，这将迫使我们使用更小的网络。在测试时，网络通过提取5个224x224patch(四个角patch和中心patch)及其水平反射(共10个patch)进行预测，并将网络的softmax层所做的预测平均到10个patch上.</p>
<p>第二种形式的数据增强包括改变训练图像中RGB通道的强度。具体地说，我们在整个过程中对ImageNet训练集中一组RGB像素值执行PCA。对每个训练图像，我们添加找到的主成分的倍数与相应特征值成比例的大小乘以一个随机变量，该随机变量由均值为零、标准差为0.1的高斯函数得出。因此，对于每个RGB图像像素 $I_{xy} = [I_{xy}^R,I_{xy}^G,I_{xy}^B]$ 我们把下列数量加起来:</p>
<script type="math/tex; mode=display">[p_1,p_2,p_3] [\alpha_{1}\beta_{1},\alpha_{2}\beta_{2},\alpha_{3}\beta_{3}]^T</script><p>$p_i$和$\beta_{i}$是第$i$个3×3协方差矩阵的特征向量和特征值的RGB像素值,特别地，$\alpha_{i}$是上述随机变量。对于特定训练图像的所有像素，每个$\alpha_{i}$只绘制一次，直到该图像再次用于训练，然后重新绘制。该方案近似地捕获了自然图像的一个重要特性，即对象标识不受光照强度和颜色变化的影响。该方案将前1位的错误率降低了1%以上。</p>
<h3><span id="dropout">Dropout</span></h3><p>结合许多不同模型的预测是减少测试错误的一种非常成功的方法，但对于已经需要几天训练的大型神经网络来说，这似乎太昂贵了。然而，有一个非常有效的模型组合版本，在培训期间只需要花费大约两倍的成本。最近引入的一种技术称为“dropout”[10]，它将每个隐藏神经元的输出设置为0，输出概率为0.5。以这种方式“脱落”的神经元不参与正向传递，也不参与反向传播。因此，每次输入被提出时，神经网络都会对不同的体系结构进行采样，但所有这些体系结构都共享权重。这种技术减少了神经元复杂的协同适应，因为神经元不能依赖于特定的其他神经元的存在。因此，它被迫学习与其他神经元的许多不同随机子集一起使用的更健壮的特性。在测试时，我们使用所有的神经元，但将它们的输出乘以0.5，这是一个合理的近似，取由指数型多退出网络产生的预测分布的几何平均值。</p>
<p>我们在图2的前两个完全连接的层中使用dropout。如果没有退出，我们的网络就会出现严重的过拟合。Dropout大约是收敛所需迭代次数的两倍。</p>
<h2><span id="details-of-learning">Details of learning</span></h2><p>我们使用随机梯度下降训练我们的模型，批量大小为128个例子，动量为0.9，重量衰减为0.0005。我们发现这一小部分的重量衰减对模型的学习很重要。换句话说，这里的重量衰减不仅仅是一个正则化器:它减少了模型的训练误差。权值w的更新规则是:</p>
<script type="math/tex; mode=display">v_{i+1} := 0.9 \cdot v_i - 0.0005 \cdot \epsilon \cdot w_i - \epsilon \cdot \left< \frac{\partial{L} }{\partial{\omega} } \vert_{\omega_i} \right>_{D_i}</script><script type="math/tex; mode=display">\omega_{i+1} = \omega_{i} + v_{i+1}</script><p>我们将每一层的权值初始化为具有标准偏差0.01的零均值高斯分布。我们在第二层、第四层、第五层卷积层以及全连通隐层中初始化神经元偏差，初始值为常数1。这种初始化通过向ReLUs提供积极的输入来加速学习的早期阶段。我们用常数0初始化剩余层中的神经元偏差。</p>
<p>我们对所有层次使用了相同的学习速度，并在整个培训过程中手动调整。当验证错误率停止随当前学习速率改进时，我们采用的启发式方法是将学习速率除以10。学习率初始化为0.01并且在终止前减少了三倍。我们在两台NVIDIA GTX 580 3GB gpu上花了5到6天的时间，通过120万幅图像的训练集，对网络进行了大约90次周期的训练。</p>
<h2><span id="results">Results</span></h2><p>我们对ILSVRC-2010的研究结果如表1所示。我们的网络达到了前1名和前5名的测试集错误率分别为37.5%和17.0%5。在ILSVRC-中获得了最好的性能，2010年的竞争分别为47.1%和28.2%，采用的方法平均了6个针对不同特征训练的稀疏编码模型的预测结果。从那时起，发表的最佳结果分别为45.7%和25.7%，方法是将两种训练在Fisher向量(FVs)上的分类器的预测平均，这两种分类器的预测是根据两种类型的密集采样特征计算出来的。</p>
<p>我们还在ILSVRC-2012比赛中输入了我们的模型，并将结果报告在表2中。自ILSVRC-2012测试集标签是不可公开的，我们不能报告我们尝试的所有模型的测试错误率。在本段的其余部分，我们交替使用验证和测试错误率，因为根据我们的经验，它们的差异不超过0.1%。本文所描述的CNN达到了前5名的错误率为18.2%。对5个类似CNNs的预测进行平均，错误率为16.4%。训练一个CNN，在最后一个池层的基础上添加了额外的第6个卷积层，来对整个ImageNet 2011年秋季发行版进行分类(1500万张图片，22K个类别)，然后在ILSVRC-2012上对其进行“微调”，得到的错误率为16.6%。在2011年秋季发布的整个版本中，预先训练过的两个CNNs与前面提到的五个CNNs的预测平均误差为15.3%。第二好的参赛作品的错误率为26.2%，该方法平均了几个训练在FVs上的分类器对不同类型的密集采样特征的预测。</p>
<p>最后，我们还报告了2009年秋季版本的错误率，ImageNet拥有10184个类别和890万幅图像。在这个数据集上，我们遵循了在文献中使用一半图像用于训练和一半图像用于测试的惯例。由于没有建立测试集，我们的分割必然不同于以前作者使用的分割，但这不会显著影响结果。我们在这个数据集上的前1和前5的错误率分别是67.4%和67.4%,40.9%，由上文所述的net实现，但在最后一个池化层的基础上增加了第6个卷积层。在这个数据集中发表的最佳结果是78.1%和60.9%。</p>
<h3><span id="qualitative-evaluations">Qualitative Evaluations</span></h3><p>图3显示了由网络的两个数据连接层学习到的卷积内核。网络已经学会了各种频率和方向选择内核，以及各种颜色的斑点。请注意这两个gpu显示的专门化，这是第3.5节中描述的连接受限的结果。GPU 1上的内核在很大程度上是颜色无关的，而GPU 2上的内核在很大程度上是特定于颜色的。这种专门化发生在每次运行期间，并且独立于任何特定的随机权重初始化(模块化gpu的重新编号)。</p>
<p>在图4的左边面板中，我们定性地评估了网络通过计算它对8张测试图像的前5个预测得到的结果。注意，即使是偏离中心的对象，比如左上角的螨虫，也可以被网络识别。排名前五的大多数品牌似乎都很合理。例如，只有其他类型的猫被认为是豹的合理标签。在某些情况下(格栅，樱桃)，有一个真正的模糊的预期焦点的照片。</p>
<p>另一种探测网络视觉知识的方法是考虑最后一个4096维隐层图像的特征激活。如果两幅图像产生的特征激活向量具有小的欧氏分离，我们可以说神经网络的高层认为它们是相似的。图4显示了来自测试集的5幅图像，以及来自训练集的6幅图像，根据这个度量，这6幅图像与每幅图像最相似。注意，在像素级别，检索到的训练图像在L2中通常与第一列中的查询图像不太接近。例如，检索到的狗和大象摆出各种各样的姿势。我们在补充材料中展示了更多测试图像的结果。</p>
<p>利用两个4096维实值向量之间的欧氏距离计算相似度是低效的，但通过训练一个自动编码器将这些向量压缩成短的二进制代码可以提高效率。这将产生一种比对原始像素[14]应用自动编码器更好的图像检索方法，原始像素[14]不使用图像标签，因此具有检索具有相似边缘模式的图像的趋势，无论它们在语义上是否相似。</p>
<h2><span id="discussion">Discussion</span></h2><p>我们的结果表明，一个大的，深卷积神经网络能够实现记录打破的结果，在一个高度挑战的数据集上使用纯监督学习。值得注意的是，如果去掉一个卷积层，我们的网络性能就会下降。例如，删除任何中间层都会导致网络的前1级性能损失约2%。所以深度对于我们取得的成果非常重要。</p>
<p>为了简化我们的实验，我们没有使用任何无监督的预训练，即使我们期望它会有所帮助，特别是如果我们获得足够的计算能力，在没有获得相应的增加标记数据量的情况下显著增加网络的大小。到目前为止，我们的结果已经有所改善，因为我们已经使我们的网络更大，训练它更长时间，但我们仍然有许多数量级的去匹配人类视觉系统的下时间路径。最后，我们希望在视频序列中使用非常大而深的卷积网络，其中时间结构提供了非常有用的信息，而这些信息在静态图像中是缺失的或不太明显的。</p>
<h2><span id="收获">收获</span></h2><ol>
<li>大规模的数据集有利于训练出低错误率模型。</li>
<li>使用ReLUs的深度卷积神经网络的训练速度是使用tanh单元的数倍。</li>
<li>Normalization(标准化)：防止某一个kernel的weight变得很大，而忽视其他太小weight的kernel。</li>
<li>防止过拟合的两种方法：扩张数据，Dropout</li>
<li>Data Augmentation(扩张数据):对图片进行旋转、缩放，或改变图片的RGB强度产生新的图片放入数据集内。</li>
<li>Dropout:每一个神经元有50%的概率输出为0。不参与到正向传播和反向传导中。但是使用它训练到收敛的时间增加了一倍。</li>
<li>多GPU并行训练可以加快训练速度。</li>
</ol>
<h2><span id="问题">问题</span></h2><ol>
<li>饱和非线性函数和不饱和非线性函数中饱和代表什么？</li>
<li>Overlapping Pooling为什么可以提高精确度？</li>
<li>深度网络的梯度衰减是怎么回事？</li>
<li>AlexNet模型为什么这样设置(模型的宽度和深度)？</li>
</ol>

                

                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/2019/06/05/pca/" data-toggle="tooltip" data-placement="top" title="主成分分析">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/2019/05/30/paper-ReducingtheDimensionality-GEH/" data-toggle="tooltip" data-placement="top" title="Reducing the Dimensionality of Data with Neural Networks">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                <!-- duoshuo Share start -->
                
                <!-- 多说 Share end-->

                <!-- 多说评论框 start -->
                
                <!-- 多说评论框 end -->

                <!-- disqus comment start -->
                
                    <div class="comment">
                        <div id="disqus_thread" class="disqus-thread"></div>
                    </div>
                
                <!--PC版
                <!--  畅言
    				<div id="SOHUCS" ></div>
    				<script charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/changyan.js" ></script>
    				<script type="text/javascript">
    				window.changyan.api.config({
    				appid: 'cytA3uKz2',
    				conf: 'prod_ec34338db0725ff75fc0186d53e47702'
    				});
				</script>
                -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      <aside id="sidebar">
        <div id="toc" class="toc-article">
        <strong class="toc-title">Contents</strong>
        
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">Abstract</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">Introduction</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">The Dataset</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">4.</span> <span class="toc-nav-text">The Architecture</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">4.1.</span> <span class="toc-nav-text">ReLU Nonlinearity</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">4.2.</span> <span class="toc-nav-text">Training on Multiple GPUs</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">4.3.</span> <span class="toc-nav-text">Local Response Normalization</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">4.4.</span> <span class="toc-nav-text">Overlapping Pooling</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">4.5.</span> <span class="toc-nav-text">Overall Architecture</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">5.</span> <span class="toc-nav-text">Reducing Overfitting</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">5.1.</span> <span class="toc-nav-text">Data Augmentation</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">5.2.</span> <span class="toc-nav-text">Dropout</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">6.</span> <span class="toc-nav-text">Details of learning</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">7.</span> <span class="toc-nav-text">Results</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">7.1.</span> <span class="toc-nav-text">Qualitative Evaluations</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">8.</span> <span class="toc-nav-text">Discussion</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">9.</span> <span class="toc-nav-text">收获</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#null"><span class="toc-nav-number">10.</span> <span class="toc-nav-text">问题</span></a></li></ol>
        
        </div>
      </aside>
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#DeepLearning" title="DeepLearning">DeepLearning</a>
                        
                          <a class="tag" href="/tags/#Paper" title="Paper">Paper</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="http://godweiyang.com/" target="_blank">Wei yang</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>




<!-- disqus embedded js code start (one page only need to embed once) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "your-disqus-ID";
    var disqus_identifier = "http://kwongyang.com/2019/06/03/paper-ImageNetClassificationCNN/";
    var disqus_url = "http://kwongyang.com/2019/06/03/paper-ImageNetClassificationCNN/";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus embedded js code start end -->




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


<script type="text/javascript" src="source/js/zooming.js"></script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                    <li>
                        <a target="_blank" href="https://user.qzone.qq.com/760030764">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-qq fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                
                
                    <li>
                        <a target="_blank" href="http://weibo.com/5044608147">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/Kwongy">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Kwong 2020 
                    <br>
                     To my beloved lover
                </p>
                <p class="copyright text-muted">
                    <!-- hitwebcounter Code START -->
                    <img src="http://hitwebcounter.com/counter/counter.php?page=7066902&style=0003&nbdigits=1&type=page&initCount=1156" title="Home Remedies For Wrinkles" Alt="Home Remedies For Wrinkles"   border="0" >
					visitors since 2018/04/20,
					<span class="post-count">177.0k words altogether</span>
				</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("http://kwongyang.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-XXXXXXXX-X';
    var _gaDomain = 'yoursite';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->






	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>
<!-- Image to hack wechat -->
<img src="http://kwongyang.com/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>

</html>
